En algoritme er en prosedyre for å løse et problem. I diskusjonen om AI blir det ofte feilaktig pekt på smarte algoritmer, som til og med kunne "slå" menneskelig intelligens. Ingenting er mindre sant: algoritmer er ekstremt dumme [6][7][8]: de gjør faktisk nøyaktig det som blir bedt om av dem (hvis ikke ville det nettopp indikere sterk AI). Men de gjør det ekstremt raskt, noe som gir en illusjon av å være "smart". Algoritmer er sterke på rask prosessering av store datamengder, som demonstreres gjennom mønstergjenkjenning av roboter (som å stille diagnoser av sykdomsbilder, selvkjørende biler, sjakkcomputere, osv.). Skaperen av et slikt algoritme kan kanskje være smart, men han har uunngåelig begrensningen at han ikke kan garantere at algoritmet er en løsning på problemet hans hvis konteksten til problemet ikke kan defineres skarpt. Referanserammen til et slikt algoritme er begrenset (som f.eks. i sjakk). I virkeligheten har mennesker imidlertid å gjøre med et mangfold av delvis overlappende kontekster innenfor et bredt referanseramme der problemstillingen ikke kan defineres skarpt. Styrken til menneskelig intelligens er nettopp at mennesker lynraskt kan bytte kontekst, for eksempel under en delvis løsning av et problem. Dette danner også grunnlaget for paradigmeskifter i problemløsninger.

Mennesker og dyr gjenkjenner mønstre hovedsakelig ubevisst, med mindre mønsteret avviker fra det vi forventer. Denne ubevisste arbeidsmåten indikerer utføring av et algoritme i det nevrale nettverket. Faktisk blir alle handlinger som noen gjør automatisk, uten å tenke over det, utført av algoritmer i det sentrale nervesystemet. Bevisstheten blir først aktiv når algoritmen stagnerer på grunn av en uventet hendelse.

Noen algoritmer kan lære, det vil si at de kan legge til nye mønstre som de ikke kjenner til i databasen sin. Faren er at et slikt nytt mønster kan forsterke en fordom. Å frigjøre en database fra fordommer er ekstremt vanskelig og krever mye menneskelig intelligens. Derfor mislykkes alle slags algoritmer jevnlig.[9]
